{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt, log10, ceil, pi\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.read_pickle('../results/organizations_profiles.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre analysis filters\n",
    "\n",
    "* Filter out banks without any transfers or with less then 2 members: functional banks\n",
    "* Replace Null values with mean values or zeroes for functional banks (depending on the variable)\n",
    "* Filter out inactive banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert transfers from seconds to minutes\n",
    "df_out['amount_tot'] = -1*df_out['amount_tot']/3600\n",
    "df_out['amount_per_member'] = -1*df_out['amount_per_member']/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_functional = df_out[(df_out.n_transf_tot > 0.0)]\n",
    "df_functional = df_functional[(df_functional.n_members>1)]\n",
    "df_active = df_functional[(df_functional.pc_active > 0.0)]\n",
    "\n",
    "\n",
    "df_func_clean=df_functional\n",
    "\n",
    "pd.set_option('use_inf_as_na', True)\n",
    "\n",
    "df_func_clean['avg_delay'].fillna((df_functional['avg_delay'].mean()), inplace=True)\n",
    "df_func_clean['avg_seniority'].fillna((df_functional['avg_seniority'].mean()), inplace=True)\n",
    "df_func_clean['avg_age'].fillna((df_functional['avg_age'].mean()), inplace=True)\n",
    "\n",
    "df_func_clean['bank_age_months'].fillna(-999, inplace=True)\n",
    "df_func_clean['threshold'].fillna(-999, inplace=True)\n",
    "\n",
    "df_func_zeroes = df_func_clean.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_desired = ['n_members',\n",
    "                       'n_active_members',\n",
    "                       'avg_delay',\n",
    "                       'n_transf_tot',\n",
    "                       #'amount_tot',\n",
    "                       'ntransf_per_member',\n",
    "                       'amount_per_member',\n",
    "                       'pc_active',\n",
    "                       'avg_seniority',\n",
    "                       'density',\n",
    "                       'median_centrality',\n",
    "                       'pc_inert',\n",
    "                       'npost_per_member']                    \n",
    "                      #'n_popular_members']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(df, variables_histogram, color='#298ba1', alpha=1.0):\n",
    "    rows = ceil(len(variables_histogram)/3)\n",
    "    fig, ax = plt.subplots(rows, 3, figsize=(14, ceil(3.5*rows)))\n",
    "    ax = ax.ravel() \n",
    "    for i, key in enumerate(variables_histogram):\n",
    "        ax[i].hist(df[key], bins=20, color=color, alpha=alpha)\n",
    "        ax[i].set_title(key)\n",
    "        \n",
    "def plot_histogram_comparisons(dfs, variables_histogram, colors, alpha=0.7):\n",
    "    df1, df2 = dfs\n",
    "    rows = ceil(len(variables_histogram)/3)\n",
    "    fig, ax = plt.subplots(rows, 3, figsize=(14, ceil(3.5*rows)))\n",
    "    ax = ax.ravel()\n",
    "    for i, key in enumerate(variables_histogram):\n",
    "        range = [min(df1[key].min(),df2[key].min()),max(df1[key].max(),df2[key].max())]\n",
    "        ax[i].hist(df1[key], bins=20, range=range, color=colors[0], alpha=alpha, density=True)\n",
    "        ax[i].hist(df2[key], bins=20, range=range, color=colors[1], alpha=alpha, density=True)\n",
    "        ax[i].set_title(key)\n",
    "    fig.savefig('histogram_compare_%i_%i'%(clusters[0],clusters[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abslog(x):\n",
    "    if x > 1:\n",
    "        return log10(x)\n",
    "    elif x < -1:\n",
    "        return -log10(-x)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_normal_vars = ['n_members',\n",
    "                   'n_active_members',\n",
    "                   'n_transf_tot',\n",
    "                   'amount_tot',\n",
    "                   'ntransf_per_member',\n",
    "                   'amount_per_member',\n",
    "                   'avg_seniority']\n",
    "to_sqrt_vars = ['avg_delay', 'pc_active', 'pc_inert', 'npost_per_member']\n",
    "rest_vars = list(set(variables_desired).difference(set(log_normal_vars+to_sqrt_vars)))\n",
    "sqrt_vars = ['sqrt_'+v for v in to_sqrt_vars]\n",
    "abslog_vars = ['abslog_'+v for v in log_normal_vars]\n",
    "mixed_vars = sqrt_vars + abslog_vars + rest_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mixed = pd.DataFrame()\n",
    "\n",
    "for var in log_normal_vars:\n",
    "    print(var)\n",
    "    df_mixed['abslog_'+var] = df_func_zeroes[var].apply(lambda x: abslog(x)) # this is wrong\n",
    "\n",
    "for var in to_sqrt_vars:\n",
    "    print(var)\n",
    "    df_mixed['sqrt_'+var] = df_func_zeroes[var].apply(lambda x: sqrt(abs(x))) # this is wrong\n",
    "    \n",
    "for var in rest_vars:\n",
    "    df_mixed[var] = df_func_zeroes[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(df_mixed, mixed_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First use PCA to reduce dimensionality to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_pca(df, dim=3):\n",
    "    X = df_mixed.values\n",
    "    pca = PCA(n_components=dim, svd_solver='full')\n",
    "    pca.fit(X)\n",
    "    X_trans = pca.transform(X)\n",
    "\n",
    "    fig, ax = plt.subplots(dim, 1, figsize=(7, 12))\n",
    "    ax = ax.ravel() \n",
    "\n",
    "    ax[0].scatter(X_trans[:, 0], X_trans[:, 1])\n",
    "    ax[1].scatter(X_trans[:, 1], X_trans[:, 2])\n",
    "    ax[2].scatter(X_trans[:, 0], X_trans[:, 2])\n",
    "    return X_trans\n",
    "\n",
    "def cluster_three_d(X, n_clusters=3):\n",
    "    y_pred = KMeans(n_clusters=n_clusters).fit_predict(X)\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(7, 12))\n",
    "    ax = ax.ravel() \n",
    "\n",
    "    ax[0].scatter(X[:, 0], X[:, 1], c=y_pred)\n",
    "    ax[1].scatter(X[:, 1], X[:, 2], c=y_pred)\n",
    "    ax[2].scatter(X[:, 0], X[:, 2], c=y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = use_pca(df_mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Kmeans to cluster\n",
    "First for 4 clusters, then for 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_4clusters = cluster_three_d(X_new, n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3clusters = cluster_three_d(X_new, n_clusters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the resulting clusters\n",
    "First for 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mixed['cluster'] = y_pred_3clusters\n",
    "df_mixed.groupby(\"cluster\").agg(['mean','median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df_func_zeroes[variables_desired]\n",
    "\n",
    "df_check['cluster'] = y_pred_3clusters\n",
    "df_check.groupby(\"cluster\").agg(['mean','median','std']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check['cluster'] = y_pred_4clusters\n",
    "df_check.groupby(\"cluster\").agg(['mean','median','std']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the values to be between 0 and 1, depending on their min max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df_func_zeroes[variables_desired]\n",
    "df_check['cluster'] = y_pred_3clusters\n",
    "\n",
    "df_normalized = pd.DataFrame()\n",
    "for v in df_check.columns.to_list():\n",
    "    if v != 'cluster':\n",
    "        if v in log_normal_vars+['avg_delay']:\n",
    "            df_normalized[v] = df_check[v].apply(lambda x: log10(1+x))\n",
    "            df_normalized[v] = (df_normalized[v]-df_normalized[v].min())/(df_normalized[v].max()-df_normalized[v].min())\n",
    "        else:\n",
    "            df_normalized[v] = (df_check[v]-df_check[v].min())/(df_check[v].max()-df_check[v].min())\n",
    "\n",
    "df_normalized['cluster'] = y_pred_3clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df_normalized.groupby(\"cluster\").median()\n",
    "df = means.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the means in a radar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spider(row, no_cluster, title, color):\n",
    " \n",
    "    # number of variable\n",
    "    categories=list(df)[1:]\n",
    "    N = len(categories)\n",
    "\n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    # Initialise the spider plot\n",
    "    ax = plt.subplot(1,no_cluster,row+1, polar=True, )\n",
    "\n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], categories, color='black', size=12)\n",
    "\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0,0.25,0.75], [\"0\",\"0.25\",\"0.75\"], color=\"grey\", size=9)\n",
    "    plt.ylim(0,0.75)\n",
    "\n",
    "    # Ind1\n",
    "    values=df.loc[row].drop('cluster').values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, color=color, linewidth=2, linestyle='solid')\n",
    "    ax.fill(angles, values, color=color, alpha=0.4)\n",
    "\n",
    "    # Add a title\n",
    "    plt.title(title, size=15, color=color, y=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df_normalized.groupby(\"cluster\").mean()\n",
    "df = means.reset_index()    \n",
    "\n",
    "# ------- PART 2: Apply to all individuals\n",
    "# initialize the figure\n",
    "#my_dpi=96\n",
    "#plt.figure(figsize=(1000/my_dpi, 1000/my_dpi), dpi=my_dpi)\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# Create a color palette:\n",
    "my_palette = plt.cm.get_cmap(\"Set2\", len(df.index))\n",
    " \n",
    "# Loop to plot\n",
    "for row in range(0, len(df.index)):\n",
    "    make_spider(row=row, no_cluster=4, title='group '+str(df['cluster'][row]), color=my_palette(row))\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.savefig('cluster_means.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df_normalized.groupby(\"cluster\").median()\n",
    "df = means.reset_index()    \n",
    "\n",
    "# ------- PART 2: Apply to all individuals\n",
    "# initialize the figure\n",
    "#my_dpi=96\n",
    "#plt.figure(figsize=(1000/my_dpi, 1000/my_dpi), dpi=my_dpi)\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# Create a color palette:\n",
    "my_palette = plt.cm.get_cmap(\"Set2\", len(df.index))\n",
    " \n",
    "# Loop to plot\n",
    "for row in range(0, len(df.index)):\n",
    "    make_spider(row=row, no_cluster=4, title='group '+str(df['cluster'][row]), color=my_palette(row))\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.savefig('cluster_media.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_functional['cluster'] = y_pred_3clusters\n",
    "# save to file\n",
    "with open('functional_kmeans_3clusters.bin', 'wb') as out:\n",
    "    df_functional.to_pickle(out)\n",
    "with open('spiderplot_3clusters.bin', 'wb') as out:\n",
    "    df_check.to_pickle(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clusters = [1, 2]\n",
    "dfs = [df_functional[df_functional['cluster'] == cluster] for cluster in clusters]\n",
    "plot_histogram_comparisons(dfs, variables_desired, [my_palette(cluster) for cluster in clusters], alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [0, 2]\n",
    "dfs = [df_functional[df_functional['cluster'] == cluster] for cluster in clusters]\n",
    "plot_histogram_comparisons(dfs, variables_desired, [my_palette(cluster) for cluster in clusters], alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_typical(df_functional, cluster, variables_desired):\n",
    "    df_cluster = df_functional[df_functional['cluster'] == cluster]\n",
    "    for key in variables_desired:\n",
    "        median = df_cluster[key].median()\n",
    "        mean = df_cluster[key].mean()\n",
    "        std = df_cluster[key].std()\n",
    "        df_cluster = df_cluster[(df_out[key] <= mean+std)]\n",
    "        df_cluster = df_cluster[(df_out[key] >= mean-std)]\n",
    "    return df_cluster[['bank_name']+variables_desired+['avg_age']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get typical for cluster 2\n",
    "get_typical(df_functional, 2, variables_desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get aytypical for cluster 2\n",
    "cluster = 2\n",
    "df_cluster = df_functional[df_functional['cluster'] == cluster]\n",
    "df_cluster = df_cluster[(df_out['n_members'] <= 10)]\n",
    "df_cluster = df_cluster[(df_out['pc_active'] == 0)]\n",
    "df_cluster = df_cluster[(df_out['n_transf_tot'] < 5)]\n",
    "\n",
    "df_cluster[['bank_name']+variables_desired+['avg_age']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get typical for cluster 1\n",
    "get_typical(df_functional, 1, variables_desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get atypical for cluster 1\n",
    "cluster = 1\n",
    "df_cluster = df_functional[df_functional['cluster'] == cluster]\n",
    "df = df_cluster[(df_cluster['pc_active'] != 0)]\n",
    "df2 = pd.concat([df,df_cluster[(df_out['bank_id'] == 148)]])\n",
    "\n",
    "df2[['bank_name']+variables_desired+['avg_age']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get typical for cluster 0\n",
    "get_typical(df_functional, 0, variables_desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get atypical for cluster 0\n",
    "cluster = 0\n",
    "df_cluster = df_functional[df_functional['cluster'] == cluster]\n",
    "df_cluster = df_cluster[(df_out['pc_inert'] <= 10)]\n",
    "df_cluster[['bank_name']+variables_desired].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get particular for cluster 0\n",
    "cluster = 0\n",
    "df_cluster = df_functional[df_functional['cluster'] == cluster]\n",
    "df_cluster = df_cluster[(df_out['n_members'] > 200)]\n",
    "df_cluster[['bank_name']+variables_desired].T\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
